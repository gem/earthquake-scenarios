{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e803765",
   "metadata": {},
   "source": [
    "# Create `Stations_Unique.csv`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65150492",
   "metadata": {},
   "source": [
    "##  Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0962ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from plots import stations_plot, gdf_epicentre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b706a100",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285143a6-01fa-4583-835e-57c52f455bfb",
   "metadata": {},
   "source": [
    "### Indicate event and list `Stations_REF.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event name\n",
    "event = '20150425_M7.8_Gorkha'\n",
    "\n",
    "stations = glob.glob(\n",
    "    os.path.join('..', '**', event, 'Recording_Stations', \n",
    "                 'Stations_*.csv'), recursive=True)\n",
    "folder = os.path.dirname(stations[0])\n",
    "\n",
    "# Raise error if 'Stations_Unique.csv' in stations\n",
    "unique = [item for item in stations \n",
    "          if 'Stations_Unique.csv' in item]\n",
    "assert len(unique) == 0, '`Stations_Unique.csv` already exists'\n",
    "\n",
    "print('Sources of data:')\n",
    "print(*stations, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53519fad-ad5c-444b-957b-4a9c45f285c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List unique references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182319de-3861-4dbb-bde0-dbfeb2a7ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations priority to create `Stations_Unique.csv` file\n",
    "# The README file includes the list and priority of reference data.\n",
    "\n",
    "priority = ['file_1', 'file_2']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48eebe8c-d725-446c-9c82-da8103209c7a",
   "metadata": {},
   "source": [
    "## Create unique file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acd11b73-cc4b-415d-8e88-d67f2d28eb95",
   "metadata": {},
   "source": [
    "### Add all sources of info based on priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c3f63-c91b-4702-b391-04463dd3c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise error if the files are not for the specified event\n",
    "assert len(priority) != 0, 'Indicate list of files as source data'\n",
    "assert event in priority[0], f'The priority files are not associated with the event {event}'\n",
    "\n",
    "# Read all sources of information\n",
    "dfs = [pd.read_csv(x) for x in priority]\n",
    "\n",
    "# Sort each data by the descending PGA_VALUE, if available\n",
    "try:\n",
    "    dfs = [df.sort_values('PGA_VALUE', \n",
    "                   ascending=False,)\n",
    "           for df in dfs]\n",
    "except KeyError:\n",
    "    print('PGA_VALUE not in columns')\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb2fa8fa-f883-482b-ab09-cbae431f7bf3",
   "metadata": {},
   "source": [
    "### Check for duplicated rows\n",
    "\n",
    "We check for two different types of duplicates:\n",
    "- `dup1` based on the STATION_ID\n",
    "- `dup2` based on the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print duplicated values\n",
    "\n",
    "def find_duplicates(df, cols):\n",
    "\n",
    "    dup = df[cols].duplicated()\n",
    "    \n",
    "    if len(df[dup]) != 0:\n",
    "        print(f'\\x1b[0;31m \\n  Found {len(df[dup])} duplicated values\\x1b[0m')\n",
    "        print(df.loc[dup, ['STATION_ID', 'REFERENCES']])\n",
    "    else:\n",
    "        print('  None')\n",
    "        \n",
    "    return dup\n",
    "\n",
    "# Explore duplicated rows across sources\n",
    "print('Check duplicates for STATION_ID')\n",
    "dup1 = find_duplicates(df, ['STATION_ID'])\n",
    "\n",
    "# Explore duplicated rows based on coordinates (5 decimal places)\n",
    "print('\\nCheck duplicates for COORDINATES')\n",
    "dup2 = find_duplicates(df.round(5), ['LONGITUDE', 'LATITUDE'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fa09279-5faf-46a4-a7a4-32d528c50ee4",
   "metadata": {},
   "source": [
    "### Remove duplicated stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated rows based on position within the files.\n",
    "# Indicate which duplicates should be removed\n",
    "#    dup = dup1 | dup2 --> union of dup1 and dup2\n",
    "#    dup = dup1 & dup2 --> intersection of dup1 and dup2\n",
    "dup = dup1 | dup2 \n",
    "\n",
    "if dup.any():\n",
    "    print('\\n Total recording stations including duplicates:', len(df))\n",
    "    print(f'\\nRemoving {len(df[dup])} duplicated rows')\n",
    "\n",
    "# Remove duplicates and drop columns with all NaN (if any)\n",
    "df2 = df[~dup].dropna(axis=1, how='all').copy()\n",
    "\n",
    "print(f'Station recordings: {len(df2)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df2fb1b0",
   "metadata": {},
   "source": [
    "## Plot recording stations in PGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974065e1-a19c-4dce-b664-402bdfc29a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create figure\n",
    "title = f'''Recording stations {event.replace('DRAFT_', '')}'''\n",
    "fig, ax = stations_plot(df2, title=title)\n",
    "\n",
    "# Add epicenter in figure\n",
    "ref_rupture = os.path.join(folder,'..', 'Rupture', 'earthquake_rupture_model_USGS.xml')\n",
    "epi = gdf_epicentre(ref_rupture)\n",
    "ax.scatter(epi.geometry.x, epi.geometry.y, \n",
    "           s=500, marker='*', color='gold', edgecolor='grey',\n",
    "           zorder=2)\n",
    "\n",
    "# # Manually adjust limits to include epicenter in figure\n",
    "# import contextily as ctx\n",
    "# ax.set_xlim(xmin, xmax)\n",
    "# ax.set_ylim(ymin, ymax)\n",
    "# ctx.add_basemap(ax, source=ctx.providers.Stamen.TonerLite, crs='EPSG:4326', alpha=0.8)\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "573fc619-d6e2-452e-b9b0-e8eef7eef5e6",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9c528-de9a-4372-ac80-7cf3be4b96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `Stations_Unique.csv`\n",
    "if len(stations) > 1:\n",
    "    file_path = os.path.join(folder, 'Stations_Unique.csv')\n",
    "    df2.to_csv(file_path, encoding='utf-8', index=False)\n",
    "    print('\\n Saving updated file in:\\n', file_path)\n",
    "else:\n",
    "    print('BE CAREFUL!!!!!',\n",
    "          'There is only 1 station. At least 2 stations needed',\n",
    "          'File not saved.', sep='\\n')\n",
    "    \n",
    "# Save figure\n",
    "output_path = os.path.join(folder, 'recording_stations.png')\n",
    "fig.savefig(output_path, facecolor=\"w\", \n",
    "            dpi=200,\n",
    "            bbox_inches='tight')\n",
    "print('figure saved in', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04537f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openquake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
